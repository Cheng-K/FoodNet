{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3ecf773-f2ee-4aad-9a66-e57398c7e67d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de8dc810-63eb-4348-b4f3-078f4b2e50f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f798ba17-79a6-486c-97e0-b20b899258c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices(\"GPU\")\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "del gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8539ace-0125-40d0-baa3-4d3684b47d1c",
   "metadata": {},
   "source": [
    "# Build a universal one hot encoder that encodes cross-dataset category and ingredients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09725b24-85d1-4ecb-9b34-3894255a1c97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OneHotEncoder:\n",
    "    def __init__(self, all_category_list, all_ingredient_list):\n",
    "        self.all_food_categories = all_category_list\n",
    "        self.all_food_categories.sort()\n",
    "        self.all_food_categories_integer_encoded = (\n",
    "            self.__encode_categories_to_integers()\n",
    "        )\n",
    "        self.all_ingredients = all_ingredient_list\n",
    "        self.all_ingredients.sort()\n",
    "        self.all_ingredients_integer_encoded = self.__encode_ingredients_to_integers()\n",
    "\n",
    "    def get_category_one_hot_encoding(self, category_name):\n",
    "        index = self.all_food_categories_integer_encoded[category_name]\n",
    "        assert index is not None, f\"{category_name} does not have an integer mapping\"\n",
    "        num_classes = len(self.all_food_categories)\n",
    "        return keras.utils.to_categorical(index, num_classes, dtype=\"uint8\")\n",
    "\n",
    "    def get_ingredients_one_hot_encoding(self, ingredient_list):\n",
    "        ingredient_list = list(\n",
    "            map(lambda x: self.__transform_ingredient_to_integer(x), ingredient_list)\n",
    "        )\n",
    "        multi_one_hot_layer = tf.keras.layers.CategoryEncoding(\n",
    "            num_tokens=len(self.all_ingredients), output_mode=\"multi_hot\"\n",
    "        )\n",
    "        return tf.cast(multi_one_hot_layer(ingredient_list), dtype=tf.uint8)\n",
    "\n",
    "    def __transform_ingredient_to_integer(self, ingredient_name):\n",
    "        index = self.all_ingredients_integer_encoded[ingredient_name]\n",
    "        assert index is not None, f\"{ingredient_name} does not have an integer mapping\"\n",
    "        return index\n",
    "\n",
    "    def __encode_categories_to_integers(self):\n",
    "        return {\n",
    "            category_name: index\n",
    "            for index, category_name in enumerate(self.all_food_categories)\n",
    "        }\n",
    "\n",
    "    def __encode_ingredients_to_integers(self):\n",
    "        return {\n",
    "            ingredient_name: index\n",
    "            for index, ingredient_name in enumerate(self.all_ingredients)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c256db-8606-4a26-aa9a-d78bae31270b",
   "metadata": {},
   "source": [
    "# Build dataset loaders for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef193835-66bf-4ded-b62c-d0d286157b35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DatasetLoader:\n",
    "    def __init__(self, image_dir, metadata_dir, dataset_name):\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.metadata_dir = Path(metadata_dir)\n",
    "        self.name = dataset_name\n",
    "        self.metadata = self.load_metadata(\n",
    "            self.metadata_dir / (\"{dataset}_metadata.csv\".format(dataset=dataset_name))\n",
    "        )\n",
    "        # Default : all_files = metadata, since metadata consists of records of all files\n",
    "        self.all_files = self.metadata.copy()\n",
    "        self.all_categories = self.extract_all_categories()\n",
    "        self.all_ingredients = self.extract_all_ingredients()\n",
    "\n",
    "    def load_image_to_arr(self, path):\n",
    "        image = tf.keras.preprocessing.image.load_img(path)\n",
    "        img_tensor = tf.keras.preprocessing.image.img_to_array(image, dtype=\"uint8\")\n",
    "        img_tensor = tf.image.resize(img_tensor, (224, 224))\n",
    "        return tf.cast(img_tensor, tf.uint8)\n",
    "\n",
    "    def load_metadata(self, path):\n",
    "        metadata = pd.read_csv(path, sep=\"\\t\")\n",
    "        new_metadata = metadata.copy()\n",
    "        new_metadata[\"dataset_name\"] = self.name\n",
    "        return new_metadata\n",
    "\n",
    "    def extract_all_categories(self):\n",
    "        return self.metadata[\"Category\"].unique().tolist()\n",
    "\n",
    "    def extract_all_ingredients(self):\n",
    "        unique_ingredients = set()\n",
    "        for ingredient_list in self.metadata[\"Ingredients\"]:\n",
    "            ingredient_list = ingredient_list.split(\",\")\n",
    "            unique_ingredients.update(ingredient_list)\n",
    "        return [*unique_ingredients]\n",
    "\n",
    "    def extract_file_pointers(self):\n",
    "        dataset_name_col = self.all_files[\"dataset_name\"]\n",
    "        index_col = self.all_files.index\n",
    "        return pd.DataFrame(\n",
    "            {\"metadata_index\": index_col, \"dataset_name\": dataset_name_col}\n",
    "        )\n",
    "\n",
    "    def get_tensors(self, index, one_hot_encoder):\n",
    "        img_dir = self.image_dir\n",
    "        row = self.all_files.loc[index]\n",
    "        img_path = img_dir / row[\"Category\"] / row[\"ID/File Name\"]\n",
    "        img_tensor = self.load_image_to_arr(img_path)\n",
    "        if img_path.suffix == \".jpeg\" or img_path.suffix == \".jpg\":\n",
    "            img_tensor = tf.io.encode_jpeg(img_tensor, format=\"rgb\")\n",
    "        elif img_path.suffix == \".png\":\n",
    "            img_tensor = tf.io.encode_png(img_tensor)\n",
    "        else:\n",
    "            assert False, \"Invalid image format present\"\n",
    "        calorie_tensor = row[\"Calorie(kcal)\"]\n",
    "        carbs_tensor = row[\"Carbohydrate(g)\"]\n",
    "        protein_tensor = row[\"Protein(g)\"]\n",
    "        fat_tensor = row[\"Fat(g)\"]\n",
    "        return img_tensor, {\n",
    "            \"category_output\": tf.constant(row[\"Category\"]),\n",
    "            \"calorie_output\": tf.constant(calorie_tensor),\n",
    "            \"carbs_output\": tf.constant(carbs_tensor),\n",
    "            \"protein_output\": tf.constant(protein_tensor),\n",
    "            \"fat_output\": tf.constant(fat_tensor),\n",
    "            \"ingredients_output\": tf.constant(row[\"Ingredients\"]),\n",
    "        }\n",
    "\n",
    "    def flatten_tensors(self, tensor):\n",
    "        result = []\n",
    "        img_data = tensor[0].numpy()\n",
    "        others_data = [value.numpy() for key, value in tensor[1].items()]\n",
    "        result.append(img_data)\n",
    "        result.extend(others_data)\n",
    "        return result\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f876af8-e890-447a-8d1c-3f07969052ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Recipes5k(DatasetLoader):\n",
    "    def __init__(self, image_dir, metadata_dir):\n",
    "        super().__init__(image_dir, metadata_dir, \"recipes5k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0a54d2-b85c-4aac-a8b2-902ad88b6f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Nutrition5k(DatasetLoader):\n",
    "    def __init__(self, image_dir, metadata_dir):\n",
    "        super().__init__(image_dir, metadata_dir, \"nutrition5k\")\n",
    "        # Modify all_files since nutrition5k metadata only consists dish_level metadata not image_level\n",
    "        self.all_files = pd.read_csv(self.metadata_dir / \"nutrition5k_all_images.csv\")\n",
    "\n",
    "    # Override method from DatasetLoader\n",
    "    def get_tensors(self, index, one_hot_encoder):\n",
    "        img_dir = self.image_dir\n",
    "        row = self.all_files.loc[index]\n",
    "        img_path = img_dir / \"generic\" / row[\"dish_id\"] / row[\"ID/File Name\"]\n",
    "        img_tensor = self.load_image_to_arr(img_path)\n",
    "        if img_path.suffix == \".jpeg\" or img_path.suffix == \".jpg\":\n",
    "            img_tensor = tf.io.encode_jpeg(img_tensor, format=\"rgb\")\n",
    "        elif img_path.suffix == \".png\":\n",
    "            img_tensor = tf.io.encode_png(img_tensor)\n",
    "        else:\n",
    "            assert False, \"Invalid image format present\"\n",
    "        dish_metadata_row = self.metadata.loc[\n",
    "            self.metadata[\"dish_id\"] == row[\"dish_id\"]\n",
    "        ].squeeze()\n",
    "        calorie_tensor = dish_metadata_row[\"Calorie(kcal)\"]\n",
    "        carbs_tensor = dish_metadata_row[\"Carbohydrate(g)\"]\n",
    "        protein_tensor = dish_metadata_row[\"Protein(g)\"]\n",
    "        fat_tensor = dish_metadata_row[\"Fat(g)\"]\n",
    "        return img_tensor, {\n",
    "            \"category_output\": tf.constant(dish_metadata_row[\"Category\"]),\n",
    "            \"calorie_output\": tf.constant(calorie_tensor),\n",
    "            \"carbs_output\": tf.constant(carbs_tensor),\n",
    "            \"protein_output\": tf.constant(protein_tensor),\n",
    "            \"fat_output\": tf.constant(fat_tensor),\n",
    "            \"ingredients_output\": tf.constant(dish_metadata_row[\"Ingredients\"]),\n",
    "        }\n",
    "\n",
    "    # Overrding the method from DatasetLoader\n",
    "    def __len__(self):\n",
    "        return len(self.all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ff5ec7-bf8c-472f-9f46-10c3042dc391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Food101(DatasetLoader):\n",
    "    def __init__(self, image_dir, metadata_dir):\n",
    "        super().__init__(image_dir, metadata_dir, \"food101\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb374be-7cf9-4042-be86-473a60a8f553",
   "metadata": {},
   "source": [
    "# Initializing one hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cc3c605-ac9d-423b-ae0d-154d1641cd39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get all the categories and ingredients from all datasets\n",
    "\n",
    "# Initialize dataset loader without one-hot encoder to get all unique category and ingredients from each dataset\n",
    "RECIPES5K = Recipes5k(\n",
    "    image_dir=\"../Food Datasets/final-dataset/images\",\n",
    "    metadata_dir=\"../Food Datasets/final-dataset/metadata\",\n",
    ")\n",
    "NUTRITION5K = Nutrition5k(\n",
    "    image_dir=\"../Food Datasets/final-dataset/images\",\n",
    "    metadata_dir=\"../Food Datasets/final-dataset/metadata\",\n",
    ")\n",
    "FOOD101 = Food101(\n",
    "    image_dir=\"../Food Datasets/final-dataset/images\",\n",
    "    metadata_dir=\"../Food Datasets/final-dataset/metadata\",\n",
    ")\n",
    "\n",
    "DATASETS = [RECIPES5K, NUTRITION5K, FOOD101]\n",
    "DATASETS_NAME = [x.name for x in DATASETS]\n",
    "\n",
    "\n",
    "def create_one_hot_encoder(datasets):\n",
    "    all_categories = []\n",
    "    all_ingredients = []\n",
    "    for x in datasets:\n",
    "        all_categories.extend(x.all_categories)\n",
    "        all_ingredients.extend(x.all_ingredients)\n",
    "    all_categories = set(all_categories)\n",
    "    all_ingredients = set(all_ingredients)\n",
    "    return OneHotEncoder([*all_categories], [*all_ingredients])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d08bb542-3d60-4033-8216-8a316cdeebf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ONE_HOT_ENCODER = create_one_hot_encoder(DATASETS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270ad655-5f17-43b3-b75e-e71aa19c9f88",
   "metadata": {},
   "source": [
    "# Building dataset pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe84dc4a-1fb4-48a1-9a2c-29b29ebbfaa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_file_data(index, dataset_index):\n",
    "    target_dataset = DATASETS[dataset_index]\n",
    "    return target_dataset.flatten_tensors(\n",
    "        target_dataset.get_tensors(index, ONE_HOT_ENCODER)\n",
    "    )\n",
    "\n",
    "\n",
    "def build_data_pipeline(datasets, sample_size=None):\n",
    "    if sample_size is None:\n",
    "        sample_size = [1.0] * len(datasets)\n",
    "    assert len(sample_size) == len(\n",
    "        datasets\n",
    "    ), \"Illegal array of sample sizes provided. Number of sample size does not match number of datasets\"\n",
    "    file_pointers = [\n",
    "        x.extract_file_pointers().sample(frac=s) for x, s in zip(datasets, sample_size)\n",
    "    ]\n",
    "    all_file_pointers = pd.concat(file_pointers).sample(frac=1, random_state=999)\n",
    "    print(f\"Total samples : {len(all_file_pointers)}\")\n",
    "\n",
    "    all_file_pointers[\"dataset_name\"] = all_file_pointers[\"dataset_name\"].apply(\n",
    "        lambda x: DATASETS_NAME.index(x)\n",
    "    )\n",
    "\n",
    "    final_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            all_file_pointers[\"metadata_index\"].tolist(),\n",
    "            all_file_pointers[\"dataset_name\"].tolist(),\n",
    "        )\n",
    "    )\n",
    "    return final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3f30aff-2b6e-48f9-9e2e-977224538d11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples : 4826\n",
      "Total samples : 101000\n",
      "Total samples : 271407\n"
     ]
    }
   ],
   "source": [
    "recipes5k_dataset = build_data_pipeline([RECIPES5K])\n",
    "food101_dataset = build_data_pipeline([FOOD101])\n",
    "nutrition5k_dataset = build_data_pipeline([NUTRITION5K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2910985d-06c6-47bb-979d-bedb7b7d1a1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(), dtype=int32, numpy=865>,\n",
       "  <tf.Tensor: shape=(), dtype=int32, numpy=0>),\n",
       " (<tf.Tensor: shape=(), dtype=int32, numpy=4413>,\n",
       "  <tf.Tensor: shape=(), dtype=int32, numpy=0>)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(recipes5k_dataset.take(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f3f017-46fc-4bdc-8eda-8d7aa69b4097",
   "metadata": {},
   "source": [
    "## Serializing Data Pipeline to TFRecord with TFDS Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8175168-8a97-4ea6-a457-279dbf582c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_DICTIONARY = tfds.features.FeaturesDict(\n",
    "    {\n",
    "        \"image_raw\": tfds.features.Image(\n",
    "            shape=(224, 224, 3), doc=\"Raw bytes of food images encoded with tf.io\"\n",
    "        ),\n",
    "        \"category\": tfds.features.Scalar(dtype=tf.string, doc=\"Category label\"),\n",
    "        \"calorie\": tfds.features.Scalar(\n",
    "            dtype=tf.float32, doc=\"Calorie of the food per gram\"\n",
    "        ),\n",
    "        \"carbs\": tfds.features.Scalar(\n",
    "            dtype=tf.float32, doc=\"Carbs of the food per gram\"\n",
    "        ),\n",
    "        \"protein\": tfds.features.Scalar(\n",
    "            dtype=tf.float32, doc=\"Protein of the food per gram\"\n",
    "        ),\n",
    "        \"fat\": tfds.features.Scalar(dtype=tf.float32, doc=\"Fat of the food per gram\"),\n",
    "        \"ingredients\": tfds.features.Scalar(\n",
    "            dtype=tf.string, doc=\"Ingredients of food separated with comma\"\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2330f2-ee56-40d7-9404-a4025452bbcf",
   "metadata": {},
   "source": [
    "### Shard and write to TFRecord file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5224e67b-b845-4493-9eee-1a39633d31a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shard_and_write(dataset, num_shards, path, dataset_name):\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        path.mkdir()\n",
    "\n",
    "    sharded_template_generator = tfds.core.ShardedFileTemplate(\n",
    "        data_dir=path.as_posix(),\n",
    "        template=\"{DATASET}-{SPLIT}-{SHARD_X_OF_Y}.{FILEFORMAT}\",\n",
    "        dataset_name=dataset_name,\n",
    "        filetype_suffix=\"tfrecord\",\n",
    "        split=\"train\",\n",
    "    )\n",
    "    shard_length = []\n",
    "    sharded_filepaths = sharded_template_generator.sharded_filepaths(num_shards)\n",
    "    for i in range(num_shards):\n",
    "        current_shard = dataset.shard(num_shards, i)\n",
    "        with tf.io.TFRecordWriter(sharded_filepaths[i].as_posix()) as writer:\n",
    "            length = 0\n",
    "            for record in current_shard.as_numpy_iterator():\n",
    "                data = get_file_data(record[0], record[1])\n",
    "                example = {\n",
    "                    \"image_raw\": data[0],\n",
    "                    \"category\": data[1],\n",
    "                    \"calorie\": data[2],\n",
    "                    \"carbs\": data[3],\n",
    "                    \"protein\": data[4],\n",
    "                    \"fat\": data[5],\n",
    "                    \"ingredients\": data[6],\n",
    "                }\n",
    "                example_bytes = FEATURE_DICTIONARY.serialize_example(example)\n",
    "                writer.write(example_bytes)\n",
    "                length += 1\n",
    "            shard_length.append(length)\n",
    "    split_info = [\n",
    "        tfds.core.SplitInfo(\n",
    "            name=\"train\",\n",
    "            shard_lengths=shard_length,\n",
    "            num_bytes=0,\n",
    "            filename_template=sharded_template_generator,\n",
    "        )\n",
    "    ]\n",
    "    tfds.folder_dataset.write_metadata(\n",
    "        data_dir=path.as_posix(),\n",
    "        features=FEATURE_DICTIONARY,\n",
    "        filename_template=\"{DATASET}-{SPLIT}-{SHARD_X_OF_Y}.{FILEFORMAT}\",\n",
    "        split_infos=split_info,\n",
    "    )\n",
    "    return shard_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3fbc0c2-c3ba-4979-81fc-4f7fa20d4f34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shard_length = shard_and_write(\n",
    "    recipes5k_dataset,\n",
    "    10,\n",
    "    f\"../Food Datasets/final-dataset/tfrecord/{RECIPES5K.name}/1.0.0\",\n",
    "    RECIPES5K.name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71a37df5-2dc7-454f-b78c-c9c5cc773843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata written. Testing by reading first example. Set check_data=False to skip.\n"
     ]
    }
   ],
   "source": [
    "shard_length2 = shard_and_write(\n",
    "    food101_dataset,\n",
    "    30,\n",
    "    f\"../Food Datasets/final-dataset/tfrecord/{FOOD101.name}/1.0.1\",\n",
    "    FOOD101.name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "580157ab-38c1-4725-82ce-2c15da26b548",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m shard_length3 \u001b[38;5;241m=\u001b[39m \u001b[43mshard_and_write\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnutrition5k_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../Food Datasets/final-dataset/tfrecord/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mNUTRITION5K\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/1.0.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mNUTRITION5K\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36mshard_and_write\u001b[1;34m(dataset, num_shards, path, dataset_name)\u001b[0m\n\u001b[0;32m     18\u001b[0m length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m current_shard\u001b[38;5;241m.\u001b[39mas_numpy_iterator():\n\u001b[1;32m---> 20\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mget_file_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     example \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_raw\u001b[39m\u001b[38;5;124m\"\u001b[39m: data[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m: data[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mingredients\u001b[39m\u001b[38;5;124m\"\u001b[39m: data[\u001b[38;5;241m6\u001b[39m],\n\u001b[0;32m     29\u001b[0m     }\n\u001b[0;32m     30\u001b[0m     example_bytes \u001b[38;5;241m=\u001b[39m FEATURE_DICTIONARY\u001b[38;5;241m.\u001b[39mserialize_example(example)\n",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36mget_file_data\u001b[1;34m(index, dataset_index)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_file_data\u001b[39m(index, dataset_index):\n\u001b[0;32m      2\u001b[0m     target_dataset \u001b[38;5;241m=\u001b[39m DATASETS[dataset_index]\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m target_dataset\u001b[38;5;241m.\u001b[39mflatten_tensors(\n\u001b[1;32m----> 4\u001b[0m         \u001b[43mtarget_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mONE_HOT_ENCODER\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     )\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mNutrition5k.get_tensors\u001b[1;34m(self, index, one_hot_encoder)\u001b[0m\n\u001b[0;32m     10\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_files\u001b[38;5;241m.\u001b[39mloc[index]\n\u001b[0;32m     11\u001b[0m img_path \u001b[38;5;241m=\u001b[39m img_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneric\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdish_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID/File Name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 12\u001b[0m img_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_image_to_arr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img_path\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m img_path\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     14\u001b[0m     img_tensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mencode_jpeg(img_tensor, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mDatasetLoader.load_image_to_arr\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_image_to_arr\u001b[39m(\u001b[38;5;28mself\u001b[39m, path):\n\u001b[1;32m---> 15\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     img_tensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimg_to_array(image, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m     img_tensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mresize(img_tensor, (\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m))\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\PY38-TF28-GPU\\lib\\site-packages\\keras\\preprocessing\\image.py:313\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.utils.load_img\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    278\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.preprocessing.image.load_img\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_img\u001b[39m(path, grayscale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m'\u001b[39m, target_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    280\u001b[0m              interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    281\u001b[0m   \u001b[38;5;124;03m\"\"\"Loads an image into PIL format.\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m  Usage:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03m      ValueError: if interpolation method is not supported.\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 313\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrayscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrayscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\PY38-TF28-GPU\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:139\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    137\u001b[0m         resample \u001b[38;5;241m=\u001b[39m _PIL_INTERPOLATION_METHODS[interpolation]\n\u001b[0;32m    138\u001b[0m         img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mresize(width_height_tuple, resample)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "shard_length3 = shard_and_write(\n",
    "    nutrition5k_dataset,\n",
    "    20,\n",
    "    f\"../Food Datasets/final-dataset/tfrecord/{NUTRITION5K.name}/1.0.0\",\n",
    "    NUTRITION5K.name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d605606-2412-45d8-a609-1818a9db999e",
   "metadata": {},
   "source": [
    "# Exported "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115d8ff3-8289-46a2-b34c-8c83e8d54cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORTED = {\"datasets\": DATASETS, \"one_hot_encoder\": ONE_HOT_ENCODER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd129b6-b1b5-489f-84f6-18a10968bd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORTED = SimpleNamespace(**EXPORTED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07aee62-b540-437e-8ce1-e4843d6a4e96",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6492e0f-92b3-47f8-a9a5-fe1d5d56ec39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PY38-TF28-GPU",
   "language": "python",
   "name": "py38-tf28-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
