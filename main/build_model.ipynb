{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de8dc810-63eb-4348-b4f3-078f4b2e50f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09725b24-85d1-4ecb-9b34-3894255a1c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotEncoder:\n",
    "    def __init__(self, all_category_list, all_ingredient_list):\n",
    "        self.all_food_categories = all_category_list\n",
    "        self.all_food_categories.sort()\n",
    "        self.all_food_categories_integer_encoded = (\n",
    "            self.__encode_categories_to_integers()\n",
    "        )\n",
    "        self.all_ingredients = all_ingredient_list\n",
    "        self.all_ingredients.sort()\n",
    "        self.all_ingredients_integer_encoded = self.__encode_ingredients_to_integers()\n",
    "\n",
    "    def get_category_one_hot_encoding(self, category_name):\n",
    "        index = self.all_food_categories_integer_encoded[category_name]\n",
    "        assert index != None, f\"{category_name} does not have an integer mapping\"\n",
    "        num_classes = len(self.all_food_categories)\n",
    "        return keras.utils.to_categorical(index, num_classes)\n",
    "\n",
    "    def get_ingredients_one_hot_encoding(self, ingredient_list):\n",
    "        ingredient_list = list(\n",
    "            map(lambda x: self.__transform_ingredient_to_integer(x), ingredient_list)\n",
    "        )\n",
    "        multi_one_hot_layer = tf.keras.layers.CategoryEncoding(\n",
    "            num_tokens=len(self.all_ingredients), output_mode=\"multi_hot\"\n",
    "        )\n",
    "        return multi_one_hot_layer(ingredient_list)\n",
    "\n",
    "    def __transform_ingredient_to_integer(self, ingredient_name):\n",
    "        index = self.all_ingredients_integer_encoded[ingredient_name]\n",
    "        assert index != None, f\"{ingredient_name} does not have an integer mapping\"\n",
    "        return index\n",
    "\n",
    "    def __encode_categories_to_integers(self):\n",
    "        return {\n",
    "            category_name: index\n",
    "            for index, category_name in enumerate(self.all_food_categories)\n",
    "        }\n",
    "\n",
    "    def __encode_ingredients_to_integers(self):\n",
    "        return {\n",
    "            ingredient_name: index\n",
    "            for index, ingredient_name in enumerate(self.all_ingredients)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f876af8-e890-447a-8d1c-3f07969052ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recipes5k:\n",
    "    def __init__(self):\n",
    "        self.dir_path = Path(\"../Food Datasets/final-dataset\")\n",
    "        self.metadata = self.load_recipe5k_metadata()\n",
    "        self.all_categories = self.extract_all_categories()\n",
    "        self.all_ingredients = self.extract_all_ingredients()\n",
    "        self.one_hot_encoder = OneHotEncoder(self.all_categories, self.all_ingredients)\n",
    "        self.entire_dataset = self.get_dataset()\n",
    "        self.training_split = 0.7\n",
    "        self.training_dataset, self.validation_dataset = self.split_data()\n",
    "\n",
    "    def load_image_to_arr(self, path):\n",
    "        image = tf.keras.preprocessing.image.load_img(path)\n",
    "        img_tensor = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        return tf.image.resize(img_tensor, (224, 224))\n",
    "\n",
    "    def load_recipe5k_metadata(self):\n",
    "        directory = self.dir_path / \"metadata\" / \"recipes5k_metadata.csv\"\n",
    "        return pd.read_csv(directory, sep=\"\\t\")\n",
    "\n",
    "    def extract_all_categories(self):\n",
    "        return self.metadata[\"Category\"].unique().tolist()\n",
    "\n",
    "    def extract_all_ingredients(self):\n",
    "        unique_ingredients = set()\n",
    "        for ingredient_list in self.metadata[\"Ingredients\"]:\n",
    "            ingredient_list = ingredient_list.split(\",\")\n",
    "            unique_ingredients.update(ingredient_list)\n",
    "        return [*unique_ingredients]\n",
    "\n",
    "    def generate_dataset(self):\n",
    "        img_dir = self.dir_path / \"images\"\n",
    "        for index, row in self.metadata.iterrows():\n",
    "            img_path = img_dir / row[\"Category\"] / (row[\"ID/File Name\"] + \".jpg\")\n",
    "            img_tensor = self.load_image_to_arr(img_path)\n",
    "            nutrition_tensor = [\n",
    "                row[\"Calorie(kcal)\"],\n",
    "                row[\"Carbohydrate(g)\"],\n",
    "                row[\"Protein(g)\"],\n",
    "                row[\"Fat(g)\"],\n",
    "            ]\n",
    "            one_hot_category_tensor = (\n",
    "                self.one_hot_encoder.get_category_one_hot_encoding(row[\"Category\"])\n",
    "            )\n",
    "            one_hot_ingredient_tensor = (\n",
    "                self.one_hot_encoder.get_ingredients_one_hot_encoding(\n",
    "                    row[\"Ingredients\"].split(\",\")\n",
    "                )\n",
    "            )\n",
    "            yield tf.constant(img_tensor), {\n",
    "                \"category_output\": tf.constant(one_hot_category_tensor),\n",
    "                \"nutrition_output\": tf.constant(nutrition_tensor),\n",
    "                \"ingredients_output\": one_hot_ingredient_tensor,\n",
    "            }\n",
    "\n",
    "    def get_dataset(self):\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            self.generate_dataset,\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=(224, 224, 3), dtype=tf.dtypes.float32),\n",
    "                {\n",
    "                    \"category_output\": tf.TensorSpec(\n",
    "                        shape=(101), dtype=tf.dtypes.float32\n",
    "                    ),\n",
    "                    \"nutrition_output\": tf.TensorSpec(\n",
    "                        shape=(4), dtype=tf.dtypes.float32\n",
    "                    ),\n",
    "                    \"ingredients_output\": tf.TensorSpec(\n",
    "                        shape=(892), dtype=tf.dtypes.float32\n",
    "                    ),\n",
    "                },\n",
    "            ),\n",
    "        )\n",
    "        # return dataset.shuffle(self.__len__() + 10, seed=1234)\n",
    "        return dataset\n",
    "\n",
    "    def split_data(self):\n",
    "        assert self.entire_dataset != None, \"No dataset is found.\"\n",
    "        training_samples = int(self.__len__() * self.training_split)\n",
    "        training_data = (\n",
    "            self.entire_dataset.take(training_samples)\n",
    "            .batch(32)\n",
    "            .prefetch(tf.data.AUTOTUNE)\n",
    "        )\n",
    "        validation_data = (\n",
    "            self.entire_dataset.skip(training_samples)\n",
    "            .take(-1)\n",
    "            .prefetch(tf.data.AUTOTUNE)\n",
    "            .batch(32)\n",
    "        )\n",
    "        return training_data, validation_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cc3c605-ac9d-423b-ae0d-154d1641cd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "recipes5k = Recipes5k()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe9c463-b851-4081-9fe5-479a3fedbe3e",
   "metadata": {},
   "source": [
    "## MobileNetv2 Convolution Base Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77295c63-1646-4600-92b7-ccdcacb6dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape=(224, 224, 3),\n",
    "        total_food_category=101,\n",
    "        total_ingredients_category=892,\n",
    "    ):\n",
    "        self.input_shape = input_shape\n",
    "        self.input_layer = self.get_input_layer()\n",
    "        self.preprocess_layers = self.get_preprocess_layers()\n",
    "        self.convolution_block = self.get_mobilenetv2_convolution_block()\n",
    "        self.shared_layers = self.get_shared_layers()\n",
    "        self.category_classification_layers = self.get_category_classification_layers(\n",
    "            total_food_category\n",
    "        )\n",
    "        self.nutrition_regression_layers = self.get_nutrition_regression_layers()\n",
    "        self.ingredients_multilabel_layers = self.get_ingredients_multilabel_layers(\n",
    "            total_ingredients_category\n",
    "        )\n",
    "\n",
    "    def get_input_layer(self):\n",
    "        return keras.Input(shape=self.input_shape)\n",
    "\n",
    "    def get_preprocess_layers(self):\n",
    "        preprocess_layers = []\n",
    "        # Data augmentation\n",
    "        preprocess_layers.append(keras.layers.RandomFlip(\"horizontal\"))\n",
    "        preprocess_layers.append(keras.layers.RandomRotation(0.2))\n",
    "        # Layer to preprocess input for mobilenetv2 architecture\n",
    "        preprocess_layers.append(keras.applications.mobilenet_v2.preprocess_input)\n",
    "\n",
    "        return preprocess_layers\n",
    "\n",
    "    def get_mobilenetv2_convolution_block(self):\n",
    "        mobilenet_v2_convolution_layers = keras.applications.MobileNetV2(\n",
    "            input_shape=self.input_shape, include_top=False, weights=\"imagenet\"\n",
    "        )\n",
    "        mobilenet_v2_convolution_layers.trainable = False\n",
    "        return mobilenet_v2_convolution_layers\n",
    "\n",
    "    def get_shared_layers(self):\n",
    "        shared_layers = []\n",
    "        shared_layers.append(keras.layers.GlobalAveragePooling2D())\n",
    "        shared_layers.append(\n",
    "            keras.layers.Dense(64, activation=\"relu\", name=\"shared_dense_1\")\n",
    "        )\n",
    "        shared_layers.append(\n",
    "            keras.layers.Dense(64, activation=\"relu\", name=\"shared_dense_2\")\n",
    "        )\n",
    "        shared_layers.append(keras.layers.Dropout(0.2))\n",
    "        return shared_layers\n",
    "\n",
    "    def get_category_classification_layers(self, total_categories):\n",
    "        category_classification_layers = []\n",
    "        # category_classification_layers.append(\n",
    "        #     keras.layers.Dense(256, activation=\"relu\", name=\"category_dense_1\")\n",
    "        # )\n",
    "        # category_classification_layers.append(\n",
    "        #     keras.layers.Dense(128, activation=\"relu\", name=\"category_dense_2\")\n",
    "        # )\n",
    "        # category_classification_layers.append(\n",
    "        #     keras.layers.Dense(64, activation=\"relu\", name=\"category_dense_3\")\n",
    "        # )\n",
    "        # category_classification_layers.append(\n",
    "        #     keras.layers.Dense(32, activation=\"relu\", name=\"category_dense_4\")\n",
    "        # )\n",
    "        category_classification_layers.append(\n",
    "            keras.layers.Dense(\n",
    "                total_categories, activation=\"softmax\", name=\"category_output\"\n",
    "            )\n",
    "        )\n",
    "        return category_classification_layers\n",
    "\n",
    "    def get_nutrition_regression_layers(self):\n",
    "        nutrition_regression_layers = []\n",
    "        nutrition_regression_layers.append(\n",
    "            keras.layers.Dense(64, activation=\"relu\", name=\"nutrition_dense_1\")\n",
    "        )\n",
    "        nutrition_regression_layers.append(\n",
    "            keras.layers.Dense(4, name=\"nutrition_output\")\n",
    "        )\n",
    "        return nutrition_regression_layers\n",
    "\n",
    "    def get_ingredients_multilabel_layers(self, total_ingredients):\n",
    "        ingredients_multilabel_layers = []\n",
    "        ingredients_multilabel_layers.append(\n",
    "            keras.layers.Dense(256, activation=\"relu\", name=\"ingredients_dense_1\")\n",
    "        )\n",
    "        ingredients_multilabel_layers.append(\n",
    "            keras.layers.Dense(128, activation=\"relu\", name=\"ingredients_dense_2\")\n",
    "        )\n",
    "        ingredients_multilabel_layers.append(\n",
    "            keras.layers.Dense(\n",
    "                total_ingredients, activation=\"sigmoid\", name=\"ingredients_output\"\n",
    "            )\n",
    "        )\n",
    "        return ingredients_multilabel_layers\n",
    "\n",
    "    def build_and_compile(\n",
    "        self,\n",
    "        category_classification_loss=keras.losses.CategoricalCrossentropy(),\n",
    "        nutrition_regression_loss=keras.losses.MeanAbsoluteError(),\n",
    "        ingredient_multilabel_loss=keras.losses.CategoricalCrossentropy(),\n",
    "        category_classification_metrics=[keras.metrics.Accuracy()],\n",
    "        nutrition_regression_metrics=[keras.metrics.MeanAbsoluteError()],\n",
    "        ingredient_multilabel_metrics=[keras.metrics.Accuracy()],\n",
    "    ):\n",
    "        model = self.input_layer\n",
    "        for layer in self.preprocess_layers:\n",
    "            model = layer(model)\n",
    "        model = self.convolution_block(model, training=False)\n",
    "        for layer in self.shared_layers:\n",
    "            model = layer(model)\n",
    "        category_classification_head = self.category_classification_layers[0](model)\n",
    "        nutrition_regression_head = self.nutrition_regression_layers[0](model)\n",
    "        ingredients_multilabel_head = self.ingredients_multilabel_layers[0](model)\n",
    "        for layer in self.category_classification_layers[1:]:\n",
    "            category_classification_head = layer(category_classification_head)\n",
    "        for layer in self.nutrition_regression_layers[1:]:\n",
    "            nutrition_regression_head = layer(nutrition_regression_head)\n",
    "        for layer in self.ingredients_multilabel_layers[1:]:\n",
    "            ingredients_multilabel_head = layer(ingredients_multilabel_head)\n",
    "        model = keras.Model(\n",
    "            inputs=self.input_layer,\n",
    "            outputs=[\n",
    "                category_classification_head,\n",
    "                nutrition_regression_head,\n",
    "                ingredients_multilabel_head,\n",
    "            ],\n",
    "            name=\"FoodNet_with_MobileNetv2\",\n",
    "        )\n",
    "        model.compile(\n",
    "            optimizer=\"adam\",\n",
    "            loss={\n",
    "                \"category_output\": category_classification_loss,\n",
    "                \"nutrition_output\": nutrition_regression_loss,\n",
    "                \"ingredients_output\": ingredient_multilabel_loss,\n",
    "            },\n",
    "            metrics={\n",
    "                \"category_output\": category_classification_metrics,\n",
    "                \"nutrition_output\": nutrition_regression_metrics,\n",
    "                \"ingredients_output\": ingredient_multilabel_metrics,\n",
    "            },\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac8919ff-bc46-4c32-9288-1f4ac93d4b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "106/106 [==============================] - 208s 2s/step - loss: 124237.6328 - category_output_loss: 97.9562 - nutrition_output_loss: 8.0869 - ingredients_output_loss: 124131.5938 - category_output_accuracy: 0.3201 - nutrition_output_mean_absolute_error: 8.0869 - ingredients_output_accuracy: 0.4338 - val_loss: 886251.0625 - val_category_output_loss: 149.7732 - val_nutrition_output_loss: 6.1889 - val_ingredients_output_loss: 886095.0000 - val_category_output_accuracy: 0.7934 - val_nutrition_output_mean_absolute_error: 6.1889 - val_ingredients_output_accuracy: 0.5867\n",
      "Epoch 2/2\n",
      "106/106 [==============================] - 193s 2s/step - loss: 28966216.0000 - category_output_loss: 1178.9541 - nutrition_output_loss: 37.6155 - ingredients_output_loss: 28965002.0000 - category_output_accuracy: 0.9672 - nutrition_output_mean_absolute_error: 37.6155 - ingredients_output_accuracy: 0.4459 - val_loss: 101292368.0000 - val_category_output_loss: 888.1473 - val_nutrition_output_loss: 17.7345 - val_ingredients_output_loss: 101291456.0000 - val_category_output_accuracy: 0.9789 - val_nutrition_output_mean_absolute_error: 17.7345 - val_ingredients_output_accuracy: 0.3284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fd01b605b0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model.build_and_compile().fit(\n",
    "    recipes5k.training_dataset,\n",
    "    epochs=2,\n",
    "    verbose=1,\n",
    "    validation_data=recipes5k.validation_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a807933-8ca7-43df-91d3-5dc9aba1137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = list(recipes5k.training_dataset.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cb2cf74-21be-44ca-954d-a61342881760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pprint(image[0][1][\"category_output\"].numpy()[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60df1ab0-bcde-40e3-b156-ac1fff33923d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79744cb-3adc-4084-8f7e-6d3da0364977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c07aee62-b540-437e-8ce1-e4843d6a4e96",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28222fc8-4370-4c36-92c2-0e3b2da0ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_recipe5k_metadata():\n",
    "    directory = (\n",
    "        Path(\"../Food Datasets/final-dataset\") / \"metadata\" / \"recipes5k_metadata.csv\"\n",
    "    )\n",
    "    return pd.read_csv(directory, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb0b37-b9a6-468d-af10-d6c8d586cb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_recipe5k_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c716989-17a8-4dec-b39b-0da69a651bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac060dd-2bd2-436d-95e0-cfca89279988",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recipes5k = Recipes5k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070186ec-97e1-4e0b-ba50-bf5ed098d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_recipes5k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207a5da6-1092-4b95-a3d1-18b611e35313",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen_func = test_recipes5k.generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a25e5e3-dabd-4919-93d0-11bfbceee04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_recipes5k.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe0cbe-5471-44f9-aaea-10e27e46892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(recipes5k.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7609ed77-693c-48e7-9e47-7ee7245d66fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1d4e65-82b9-46b1-ab3f-d34c024446b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = test_model.build_and_compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6d8a3d-53d9-4ae1-88b3-b88181b8d955",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7d7b51-a6d0-4816-8840-086fa718ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.fit(\n",
    "    x=test_recipes5k.training_dataset,\n",
    "    epochs=1,\n",
    "    verbose=1,\n",
    "    validation_data=test_recipes5k.validation_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63930dc8-5c6c-4f8a-9242-1a5e24d46cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.constant([[[1, 2, 3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9608f3-5f40-42bf-ba5e-190e7974bde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2e37c-0a32-4163-9614-efeec8704533",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.expand_dims(test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6bcc84-7c59-454b-adcf-eeaf96eaa036",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recipes5k.training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7c37e2-0a30-40f3-b0d3-820bc68cad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recipes5k.validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a044e7-d57f-4f94-9c47-0fbbb209631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 0\n",
    "for x in test_recipes5k.training_dataset:\n",
    "    row += 1\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd49f7bb-0cf2-48ec-a22c-71661efed140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2-GPU-PY310",
   "language": "python",
   "name": "tf2-gpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
